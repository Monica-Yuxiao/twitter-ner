{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pytorch 0.3.1\n",
    "import io, os, sys, types\n",
    "\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import crf\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "\n",
    "\n",
    "\n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "from crf import CRF\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yuxiaozhang/Documents/19spring/cs273/project\n",
      "tensor([[0.0291, 0.0302, 0.7406],\n",
      "        [0.2903, 0.8046, 0.6480],\n",
      "        [0.7522, 0.1258, 0.0423],\n",
      "        [0.4783, 0.9455, 0.1327],\n",
      "        [0.0737, 0.5042, 0.0991]])\n"
     ]
    }
   ],
   "source": [
    "# test torch is working\n",
    "print(os.getcwd())\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two dice one is fair, one is loaded\n",
    "fair_dice = np.array([1/6]*6)\n",
    "loaded_dice = np.array([0.04,0.04,0.04,0.04,0.04,0.8])\n",
    "\n",
    "probabilities = {'fair': fair_dice,\n",
    "                'loaded': loaded_dice}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.79175947 -3.21887582]\n",
      " [-1.79175947 -3.21887582]\n",
      " [-1.79175947 -3.21887582]\n",
      " [-1.79175947 -3.21887582]\n",
      " [-1.79175947 -3.21887582]\n",
      " [-1.79175947 -0.22314355]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# if dice is fair at time t, 0.6 chance we stay fair, 0.4 chance it is loaded at time 2\n",
    "transition_mat = {'fair': np.array([0.6, 0.4, 0.0]),\n",
    "                 'loaded': np.array([0.3, 0.7, 0.0]),\n",
    "                 'start': np.array([0.5, 0.5, 0.0])}\n",
    "states = ['fair', 'loaded', 'start']\n",
    "state2ix = {'fair': 0,\n",
    "           'loaded': 1,\n",
    "           'start': 2}\n",
    "\n",
    "# print(fair_dice.reshape(-1,1))\n",
    "# print(loaded_dice.reshape(-1,1))\n",
    "# h1 = fair_dice.reshape(-1,1)\n",
    "# h2 = loaded_dice.reshape(-1,1)\n",
    "# print(np.hstack([h1, h2]))\n",
    "log_likelihood = np.hstack([np.log(fair_dice).reshape(-1,1),\n",
    "                            np.log(loaded_dice).reshape(-1,1)])\n",
    "print(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(n_timesteps):\n",
    "    data = np.zeros(n_timesteps)\n",
    "    prev_state = 'start'\n",
    "    state_list = np.zeros(n_timesteps)\n",
    "    for n in range(n_timesteps):\n",
    "        next_state = np.random.choice(states, p=transition_mat[prev_state])\n",
    "        state_list[n] = state2ix[next_state]\n",
    "        next_data = np.random.choice([0,1,2,3,4,5], p=probabilities[next_state])\n",
    "        data[n] = next_data\n",
    "        prev_state = next_state\n",
    "    return data, state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 15\n",
    "rolls = np.zeros((5000, n_obs)).astype(int)\n",
    "targets = np.zeros((5000, n_obs)).astype(int)\n",
    "\n",
    "for i in range(5000):\n",
    "    data, dices = simulate_data(n_obs)\n",
    "    rolls[i] = data.reshape(1, -1).astype(int)\n",
    "    targets[i] = dices.reshape(1, -1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.79175947 -3.21887582]\n",
      " [-1.79175947 -3.21887582]\n",
      " [-1.79175947 -3.21887582]\n",
      " [-1.79175947 -3.21887582]\n",
      " [-1.79175947 -3.21887582]\n",
      " [-1.79175947 -0.22314355]]\n",
      "** initializing transition **\n",
      "** initializing loglikelihood **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuxiaozhang/Documents/19spring/cs273/project/crf.py:24: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  self.transition = torch.nn.init.normal(nn.Parameter(torch.randn(n_dice, n_dice + 1)), -1, 0.1)\n"
     ]
    }
   ],
   "source": [
    "print(log_likelihood)\n",
    "model = crf.CRF(2, log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "\n",
    "def crf_train_loop(model, rolls, targets, n_epochs, learning_rate=0.01):\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    for epoch in range(n_epochs):\n",
    "        batch_loss = []\n",
    "        N = rolls.shape[0]\n",
    "        model.zero_grad()\n",
    "        for index, (roll, labels) in enumerate(zip(rolls, targets)):\n",
    "            # Forward Pass\n",
    "            neg_log_likelihood = model.neg_log_likelihood(roll, labels)\n",
    "            batch_loss.append(neg_log_likelihood)\n",
    "            \n",
    "            if index % 50 == 0:\n",
    "                ll = torch.cat(batch_loss).mean()\n",
    "                ll.backward()\n",
    "                optimizer.step()\n",
    "                print(\"Epoch {}: Batch {}/{} loss is {:.4f}\".format(epoch, index//50, N//50, ll.data.numpy()[0]))\n",
    "                batch_loss = []\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** inside _data_to_likelihood **\n",
      "** inside numerator **\n",
      "self.transition:\n",
      " Parameter containing:\n",
      "tensor([[-1.0393, -0.8443, -0.9535],\n",
      "        [-1.1236, -1.1344, -1.0686]], requires_grad=True)\n",
      "self.transition[:, self.n_states]:\n",
      " tensor([-0.9535, -1.0686], grad_fn=<SelectBackward>)\n",
      "loglikelihoods:\n",
      " tensor([[-1.7918, -0.2231],\n",
      "        [-1.7918, -0.2231],\n",
      "        [-1.7918, -3.2189],\n",
      "        [-1.7918, -0.2231],\n",
      "        [-1.7918, -0.2231],\n",
      "        [-1.7918, -3.2189],\n",
      "        [-1.7918, -3.2189],\n",
      "        [-1.7918, -3.2189],\n",
      "        [-1.7918, -3.2189],\n",
      "        [-1.7918, -3.2189],\n",
      "        [-1.7918, -3.2189],\n",
      "        [-1.7918, -3.2189],\n",
      "        [-1.7918, -3.2189],\n",
      "        [-1.7918, -0.2231],\n",
      "        [-1.7918, -0.2231]])\n",
      "loglikelihoods[0].view(1, -1):\n",
      " tensor([[-1.7918, -0.2231]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 0) cannot be concatenated",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7ac210a3a0dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf_train_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrolls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-f7125b80216e>\u001b[0m in \u001b[0;36mcrf_train_loop\u001b[0;34m(model, rolls, targets, n_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrolls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Forward Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mneg_log_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/19spring/cs273/project/crf.py\u001b[0m in \u001b[0;36mneg_log_likelihood\u001b[0;34m(self, rolls, states)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0msequence_loglik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_likelihood_numerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloglikelihoods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_likelihood_denominator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloglikelihoods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdenominator\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msequence_loglik\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/19spring/cs273/project/crf.py\u001b[0m in \u001b[0;36m_compute_likelihood_denominator\u001b[0;34m(self, loglikelihoods)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0malpha_t_next_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_alpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeature_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0malpha_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_sum_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_t_next_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mprev_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_sum_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 0) cannot be concatenated"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model = crf_train_loop(model, rolls, targets, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
